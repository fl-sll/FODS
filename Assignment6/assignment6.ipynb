{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\edwar\\AppData\\Roaming\\Python\\Python39\\site-packages\\IPython\\core\\interactiveshell.py:3378: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version.\n",
      "\n",
      "\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "b'Skipping line 6452: expected 8 fields, saw 9\\nSkipping line 10824: expected 8 fields, saw 9\\nSkipping line 14769: expected 8 fields, saw 9\\nSkipping line 14936: expected 8 fields, saw 9\\nSkipping line 15690: expected 8 fields, saw 10\\nSkipping line 17320: expected 8 fields, saw 9\\nSkipping line 18095: expected 8 fields, saw 9\\nSkipping line 28443: expected 8 fields, saw 9\\nSkipping line 33098: expected 8 fields, saw 9\\nSkipping line 36394: expected 8 fields, saw 12\\nSkipping line 42628: expected 8 fields, saw 9\\nSkipping line 43667: expected 8 fields, saw 10\\nSkipping line 51751: expected 8 fields, saw 9\\nSkipping line 52174: expected 8 fields, saw 9\\nSkipping line 56901: expected 8 fields, saw 10\\nSkipping line 58600: expected 8 fields, saw 10\\nSkipping line 60739: expected 8 fields, saw 10\\n'\n",
      "b'Skipping line 65756: expected 8 fields, saw 9\\nSkipping line 67924: expected 8 fields, saw 9\\nSkipping line 68134: expected 8 fields, saw 9\\nSkipping line 70764: expected 8 fields, saw 11\\nSkipping line 72572: expected 8 fields, saw 12\\nSkipping line 74291: expected 8 fields, saw 9\\nSkipping line 77336: expected 8 fields, saw 9\\nSkipping line 79974: expected 8 fields, saw 9\\nSkipping line 88000: expected 8 fields, saw 10\\nSkipping line 88698: expected 8 fields, saw 9\\nSkipping line 88980: expected 8 fields, saw 9\\nSkipping line 90210: expected 8 fields, saw 12\\nSkipping line 92038: expected 8 fields, saw 11\\nSkipping line 93118: expected 8 fields, saw 9\\nSkipping line 94130: expected 8 fields, saw 9\\nSkipping line 95058: expected 8 fields, saw 9\\nSkipping line 102341: expected 8 fields, saw 9\\nSkipping line 104082: expected 8 fields, saw 9\\nSkipping line 104319: expected 8 fields, saw 10\\nSkipping line 105641: expected 8 fields, saw 9\\nSkipping line 106183: expected 8 fields, saw 9\\nSkipping line 108529: expected 8 fields, saw 10\\nSkipping line 108900: expected 8 fields, saw 9\\nSkipping line 109643: expected 8 fields, saw 9\\nSkipping line 114070: expected 8 fields, saw 10\\nSkipping line 116049: expected 8 fields, saw 9\\nSkipping line 119548: expected 8 fields, saw 12\\nSkipping line 121768: expected 8 fields, saw 9\\nSkipping line 123756: expected 8 fields, saw 11\\nSkipping line 127265: expected 8 fields, saw 9\\nSkipping line 128631: expected 8 fields, saw 10\\nSkipping line 130794: expected 8 fields, saw 11\\n'\n",
      "b'Skipping line 131589: expected 8 fields, saw 9\\nSkipping line 135121: expected 8 fields, saw 9\\nSkipping line 137613: expected 8 fields, saw 10\\nSkipping line 137965: expected 8 fields, saw 9\\nSkipping line 141433: expected 8 fields, saw 9\\nSkipping line 141437: expected 8 fields, saw 9\\nSkipping line 144058: expected 8 fields, saw 9\\nSkipping line 147368: expected 8 fields, saw 12\\nSkipping line 147902: expected 8 fields, saw 9\\nSkipping line 150789: expected 8 fields, saw 9\\nSkipping line 152662: expected 8 fields, saw 9\\nSkipping line 154679: expected 8 fields, saw 10\\nSkipping line 157128: expected 8 fields, saw 10\\nSkipping line 161889: expected 8 fields, saw 9\\nSkipping line 165306: expected 8 fields, saw 9\\nSkipping line 167342: expected 8 fields, saw 9\\nSkipping line 169037: expected 8 fields, saw 9\\nSkipping line 170503: expected 8 fields, saw 9\\nSkipping line 172648: expected 8 fields, saw 9\\nSkipping line 173779: expected 8 fields, saw 10\\nSkipping line 180189: expected 8 fields, saw 10\\nSkipping line 180664: expected 8 fields, saw 9\\nSkipping line 185738: expected 8 fields, saw 9\\nSkipping line 185882: expected 8 fields, saw 9\\nSkipping line 188934: expected 8 fields, saw 9\\nSkipping line 193160: expected 8 fields, saw 10\\nSkipping line 193583: expected 8 fields, saw 11\\nSkipping line 195879: expected 8 fields, saw 9\\nSkipping line 196652: expected 8 fields, saw 9\\n'\n",
      "b'Skipping line 197950: expected 8 fields, saw 9\\nSkipping line 198109: expected 8 fields, saw 9\\nSkipping line 207489: expected 8 fields, saw 9\\nSkipping line 208011: expected 8 fields, saw 10\\nSkipping line 208474: expected 8 fields, saw 9\\nSkipping line 209388: expected 8 fields, saw 9\\nSkipping line 211908: expected 8 fields, saw 10\\nSkipping line 212579: expected 8 fields, saw 9\\nSkipping line 214872: expected 8 fields, saw 10\\nSkipping line 216364: expected 8 fields, saw 9\\nSkipping line 219797: expected 8 fields, saw 9\\nSkipping line 219926: expected 8 fields, saw 10\\nSkipping line 220330: expected 8 fields, saw 9\\nSkipping line 220626: expected 8 fields, saw 9\\nSkipping line 221180: expected 8 fields, saw 10\\nSkipping line 221502: expected 8 fields, saw 9\\nSkipping line 227933: expected 8 fields, saw 11\\nSkipping line 228687: expected 8 fields, saw 10\\nSkipping line 228957: expected 8 fields, saw 10\\nSkipping line 229655: expected 8 fields, saw 9\\nSkipping line 232561: expected 8 fields, saw 9\\nSkipping line 238333: expected 8 fields, saw 10\\nSkipping line 238927: expected 8 fields, saw 9\\nSkipping line 239775: expected 8 fields, saw 9\\nSkipping line 241757: expected 8 fields, saw 10\\nSkipping line 244864: expected 8 fields, saw 13\\nSkipping line 245414: expected 8 fields, saw 9\\nSkipping line 245933: expected 8 fields, saw 9\\nSkipping line 246351: expected 8 fields, saw 9\\nSkipping line 251296: expected 8 fields, saw 9\\nSkipping line 251297: expected 8 fields, saw 9\\nSkipping line 253930: expected 8 fields, saw 9\\nSkipping line 259941: expected 8 fields, saw 9\\nSkipping line 260581: expected 8 fields, saw 9\\nSkipping line 261529: expected 8 fields, saw 9\\n'\n",
      "b'Skipping line 267207: expected 8 fields, saw 14\\nSkipping line 269121: expected 8 fields, saw 9\\n'\n",
      "C:\\Users\\edwar\\AppData\\Roaming\\Python\\Python39\\site-packages\\IPython\\core\\interactiveshell.py:3378: DtypeWarning: Columns (3) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 271264 entries, 0 to 271263\n",
      "Data columns (total 8 columns):\n",
      " #   Column               Non-Null Count   Dtype \n",
      "---  ------               --------------   ----- \n",
      " 0   ISBN                 271264 non-null  object\n",
      " 1   Book-Title           271264 non-null  object\n",
      " 2   Book-Author          271263 non-null  object\n",
      " 3   Year-Of-Publication  271264 non-null  object\n",
      " 4   Publisher            271262 non-null  object\n",
      " 5   Image-URL-S          271264 non-null  object\n",
      " 6   Image-URL-M          271264 non-null  object\n",
      " 7   Image-URL-L          271261 non-null  object\n",
      "dtypes: object(8)\n",
      "memory usage: 16.6+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "books_df = pd.read_csv('BX-Books.csv',encoding='latin-1', delimiter=',',error_bad_lines = False)\n",
    "ratings_df = pd.read_csv('BX-Book-Ratings.csv',encoding='latin-1', delimiter=',',error_bad_lines = False)\n",
    "print(books_df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               Title Rating\n",
      "0                                Classical Mythology      0\n",
      "1                                       Clara Callan      5\n",
      "2                                           Jane Doe      5\n",
      "3                                      The Testament      0\n",
      "4  Decorative Stamping: Hundreds of Projects for ...      7\n"
     ]
    }
   ],
   "source": [
    "userInput = [{'Title':'Classical Mythology', 'Rating':'0'},\n",
    "            {'Title':'Clara Callan', 'Rating':'5'},\n",
    "            {'Title':'Jane Doe','Rating':'5'},\n",
    "            {'Title':'The Testament','Rating':'0'},\n",
    "            {'Title':'Decorative Stamping: Hundreds of Projects for Your Home','Rating':'7'}]\n",
    "        \n",
    "inputBooks = pd.DataFrame(userInput)\n",
    "print(inputBooks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         ISBN                Title Rating\n",
      "0  0195153448  Classical Mythology      0\n",
      "1  0002005018         Clara Callan      5\n"
     ]
    }
   ],
   "source": [
    "inputID = books_df[books_df['Book-Title'].isin(inputBooks['Title'].tolist())]\n",
    "inputBooks = pd.merge(inputID,inputBooks,left_index=True, right_index=True)\n",
    "inputBooks = inputBooks[['ISBN','Title','Rating']]\n",
    "print(inputBooks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            User-ID  Book-Rating\n",
      "ISBN                            \n",
      "0002005018       14           14\n",
      "0195153448        1            1\n"
     ]
    }
   ],
   "source": [
    "userSubset = ratings_df[ratings_df['ISBN'].isin(inputBooks['ISBN'].tolist())]\n",
    "print(userSubset.groupby('ISBN').count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('0002005018',          User-ID        ISBN  Book-Rating\n",
      "9563           8  0002005018            5\n",
      "43178      11400  0002005018            0\n",
      "45340      11676  0002005018            8\n",
      "188244     41385  0002005018            0\n",
      "283152     67544  0002005018            8\n",
      "354414     85526  0002005018            0\n",
      "399690     96054  0002005018            0\n",
      "490342    116866  0002005018            9\n",
      "508051    123629  0002005018            9\n",
      "734221    177458  0002005018            0\n",
      "828273    200273  0002005018            8\n",
      "871535    210926  0002005018            9\n",
      "903613    219008  0002005018            7\n",
      "1096853   263325  0002005018            6), ('0195153448',       User-ID        ISBN  Book-Rating\n",
      "9561        2  0195153448            0)]\n"
     ]
    }
   ],
   "source": [
    "userSubsetGroup = userSubset.groupby(['ISBN'])\n",
    "\n",
    "def take_3_elem(x):\n",
    "    # print (len(x[1]))\n",
    "    return len(x[1])\n",
    "    \n",
    "userSubsetGroup = sorted(userSubsetGroup, key=take_3_elem, reverse=True)\n",
    "\n",
    "userSubsetGroup = userSubsetGroup[0:100]\n",
    "print(userSubsetGroup[0:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pearsonCorrelationDict = {}\n",
    "\n",
    "#For every user group in our subset\n",
    "for name, group in userSubsetGroup:\n",
    "\n",
    "    #Let's start by sorting the input and current user group so the values aren't mixed up later on\n",
    "    group = group.sort_values(by='ISBN')\n",
    "    inputBooks = inputBooks.sort_values(by='ISBN')\n",
    "\n",
    "    #Get the N for the formula\n",
    "    nRatings = len(group)\n",
    "\n",
    "    #Get the review scores for the movies that they both have in common\n",
    "    temp_df = inputBooks[inputBooks['ISBN'].isin(group['ISBN'].tolist())]\n",
    "\n",
    "    #And then store them in a temporary buffer variable in a list format to facilitate future calculations\n",
    "    tempRatingList = temp_df['ISBN'].tolist()\n",
    "\n",
    "    tempR = []\n",
    "    for i in tempRatingList:\n",
    "        tempR.append(int(i))\n",
    "\n",
    "    tempG = []\n",
    "    #Let's also put the current user group reviews in a list format\n",
    "    tempGroupList = group['ISBN'].tolist()\n",
    "\n",
    "    for i in tempGroupList:\n",
    "        tempG.append(int(i))\n",
    "\n",
    "    \n",
    "    #Now let's calculate the pearson correlation between two users, so called, x and y manually (check the formula from week 7 slide)\n",
    "    Sxx = sum([pow(i,2) for i in tempR]) - pow(sum(tempR),2)/int(nRatings)\n",
    "    Syy = sum([pow(i,2) for i in tempG]) - pow(sum(tempG),2)/int(nRatings)\n",
    "    Sxy = sum( i*j for i, j in zip(tempR, tempG)) - sum(tempR)*sum(tempG)/int(nRatings)\n",
    "\n",
    "    #If the denominator is different than zero, then divide, else, 0 correlation.\n",
    "    if Sxx != 0 and Syy != 0:\n",
    "        pearsonCorrelationDict[name] = Sxy/sqrt(Sxx*Syy)\n",
    "    else:\n",
    "        pearsonCorrelationDict[name] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   similarityIndex      userId\n",
      "0                0  0002005018\n",
      "1                0  0195153448\n"
     ]
    }
   ],
   "source": [
    "pearsonDF = pd.DataFrame.from_dict(pearsonCorrelationDict, orient='index')\n",
    "pearsonDF.columns = ['similarityIndex']\n",
    "pearsonDF['userId'] = pearsonDF.index\n",
    "pearsonDF.index = range(len(pearsonDF))\n",
    "print(pearsonDF.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   similarityIndex      userId\n",
      "0                0  0002005018\n",
      "1                0  0195153448\n"
     ]
    }
   ],
   "source": [
    "topUsers=pearsonDF.sort_values(by='similarityIndex', ascending=False)[0:50]\n",
    "print(topUsers.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   similarityIndex      userId  User-ID        ISBN  Book-Rating\n",
      "0                0  0002005018   276725  034545104X            0\n",
      "1                0  0195153448   276726  0155061224            5\n"
     ]
    }
   ],
   "source": [
    "topUsersRating=topUsers.merge(ratings_df, left_index=True, right_index=True)\n",
    "print(topUsersRating.head(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   similarityIndex      userId  User-ID        ISBN  Book-Rating  \\\n",
      "0                0  0002005018   276725  034545104X            0   \n",
      "1                0  0195153448   276726  0155061224            5   \n",
      "\n",
      "   weightedRating  \n",
      "0               0  \n",
      "1               0  \n"
     ]
    }
   ],
   "source": [
    "topUsersRating['weightedRating'] = topUsersRating['similarityIndex']*topUsersRating['Book-Rating']\n",
    "print(topUsersRating.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            sum_similarityIndex  sum_weightedRating\n",
      "ISBN                                               \n",
      "0155061224                    0                   0\n",
      "034545104X                    0                   0\n"
     ]
    }
   ],
   "source": [
    "tempTopUsersRating = topUsersRating.groupby('ISBN').sum()[['similarityIndex','weightedRating']]\n",
    "tempTopUsersRating.columns = ['sum_similarityIndex','sum_weightedRating']\n",
    "print(tempTopUsersRating.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            weighted average recommendation score        ISBN\n",
      "ISBN                                                         \n",
      "0155061224                                    NaN  0155061224\n",
      "034545104X                                    NaN  034545104X\n"
     ]
    }
   ],
   "source": [
    "recommendation_df = pd.DataFrame()\n",
    "\n",
    "recommendation_df['weighted average recommendation score'] = tempTopUsersRating['sum_weightedRating']/tempTopUsersRating['sum_similarityIndex']\n",
    "recommendation_df['ISBN'] = tempTopUsersRating.index\n",
    "print(recommendation_df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            weighted average recommendation score        ISBN\n",
      "ISBN                                                         \n",
      "0155061224                                    NaN  0155061224\n",
      "034545104X                                    NaN  034545104X\n"
     ]
    }
   ],
   "source": [
    "recommendation_df = recommendation_df.sort_values(by='weighted average recommendation score', ascending=False)\n",
    "print(recommendation_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              ISBN            Book-Title Book-Author\n",
      "2966    034545104X  Flesh Tones: A Novel  M. J. Rose\n",
      "225735  0155061224      Rites of Passage  Judith Rae\n"
     ]
    }
   ],
   "source": [
    "recommended_books=books_df.loc[books_df['ISBN'].isin(recommendation_df['ISBN'])]\n",
    "\n",
    "#we don't want to recommend the same movie\n",
    "recommended_books=recommended_books.loc[~recommended_books.ISBN.isin(userSubset['ISBN'])]\n",
    "\n",
    "recommended_books = recommended_books.drop(['Year-Of-Publication','Publisher','Image-URL-S','Image-URL-M','Image-URL-L'], axis=1)\n",
    "\n",
    "print(recommended_books)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "11938c6bc6919ae2720b4d5011047913343b08a43b18698fd82dedb0d4417594"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
