{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\edwar\\AppData\\Roaming\\Python\\Python39\\site-packages\\IPython\\core\\interactiveshell.py:3378: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version.\n",
      "\n",
      "\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "b'Skipping line 6452: expected 8 fields, saw 9\\nSkipping line 10824: expected 8 fields, saw 9\\nSkipping line 14769: expected 8 fields, saw 9\\nSkipping line 14936: expected 8 fields, saw 9\\nSkipping line 15690: expected 8 fields, saw 10\\nSkipping line 17320: expected 8 fields, saw 9\\nSkipping line 18095: expected 8 fields, saw 9\\nSkipping line 28443: expected 8 fields, saw 9\\nSkipping line 33098: expected 8 fields, saw 9\\nSkipping line 36394: expected 8 fields, saw 12\\nSkipping line 42628: expected 8 fields, saw 9\\nSkipping line 43667: expected 8 fields, saw 10\\nSkipping line 51751: expected 8 fields, saw 9\\nSkipping line 52174: expected 8 fields, saw 9\\nSkipping line 56901: expected 8 fields, saw 10\\nSkipping line 58600: expected 8 fields, saw 10\\nSkipping line 60739: expected 8 fields, saw 10\\n'\n",
      "b'Skipping line 65756: expected 8 fields, saw 9\\nSkipping line 67924: expected 8 fields, saw 9\\nSkipping line 68134: expected 8 fields, saw 9\\nSkipping line 70764: expected 8 fields, saw 11\\nSkipping line 72572: expected 8 fields, saw 12\\nSkipping line 74291: expected 8 fields, saw 9\\nSkipping line 77336: expected 8 fields, saw 9\\nSkipping line 79974: expected 8 fields, saw 9\\nSkipping line 88000: expected 8 fields, saw 10\\nSkipping line 88698: expected 8 fields, saw 9\\nSkipping line 88980: expected 8 fields, saw 9\\nSkipping line 90210: expected 8 fields, saw 12\\nSkipping line 92038: expected 8 fields, saw 11\\nSkipping line 93118: expected 8 fields, saw 9\\nSkipping line 94130: expected 8 fields, saw 9\\nSkipping line 95058: expected 8 fields, saw 9\\nSkipping line 102341: expected 8 fields, saw 9\\nSkipping line 104082: expected 8 fields, saw 9\\nSkipping line 104319: expected 8 fields, saw 10\\nSkipping line 105641: expected 8 fields, saw 9\\nSkipping line 106183: expected 8 fields, saw 9\\nSkipping line 108529: expected 8 fields, saw 10\\nSkipping line 108900: expected 8 fields, saw 9\\nSkipping line 109643: expected 8 fields, saw 9\\nSkipping line 114070: expected 8 fields, saw 10\\nSkipping line 116049: expected 8 fields, saw 9\\nSkipping line 119548: expected 8 fields, saw 12\\nSkipping line 121768: expected 8 fields, saw 9\\nSkipping line 123756: expected 8 fields, saw 11\\nSkipping line 127265: expected 8 fields, saw 9\\nSkipping line 128631: expected 8 fields, saw 10\\nSkipping line 130794: expected 8 fields, saw 11\\n'\n",
      "b'Skipping line 131589: expected 8 fields, saw 9\\nSkipping line 135121: expected 8 fields, saw 9\\nSkipping line 137613: expected 8 fields, saw 10\\nSkipping line 137965: expected 8 fields, saw 9\\nSkipping line 141433: expected 8 fields, saw 9\\nSkipping line 141437: expected 8 fields, saw 9\\nSkipping line 144058: expected 8 fields, saw 9\\nSkipping line 147368: expected 8 fields, saw 12\\nSkipping line 147902: expected 8 fields, saw 9\\nSkipping line 150789: expected 8 fields, saw 9\\nSkipping line 152662: expected 8 fields, saw 9\\nSkipping line 154679: expected 8 fields, saw 10\\nSkipping line 157128: expected 8 fields, saw 10\\nSkipping line 161889: expected 8 fields, saw 9\\nSkipping line 165306: expected 8 fields, saw 9\\nSkipping line 167342: expected 8 fields, saw 9\\nSkipping line 169037: expected 8 fields, saw 9\\nSkipping line 170503: expected 8 fields, saw 9\\nSkipping line 172648: expected 8 fields, saw 9\\nSkipping line 173779: expected 8 fields, saw 10\\nSkipping line 180189: expected 8 fields, saw 10\\nSkipping line 180664: expected 8 fields, saw 9\\nSkipping line 185738: expected 8 fields, saw 9\\nSkipping line 185882: expected 8 fields, saw 9\\nSkipping line 188934: expected 8 fields, saw 9\\nSkipping line 193160: expected 8 fields, saw 10\\nSkipping line 193583: expected 8 fields, saw 11\\nSkipping line 195879: expected 8 fields, saw 9\\nSkipping line 196652: expected 8 fields, saw 9\\n'\n",
      "b'Skipping line 197950: expected 8 fields, saw 9\\nSkipping line 198109: expected 8 fields, saw 9\\nSkipping line 207489: expected 8 fields, saw 9\\nSkipping line 208011: expected 8 fields, saw 10\\nSkipping line 208474: expected 8 fields, saw 9\\nSkipping line 209388: expected 8 fields, saw 9\\nSkipping line 211908: expected 8 fields, saw 10\\nSkipping line 212579: expected 8 fields, saw 9\\nSkipping line 214872: expected 8 fields, saw 10\\nSkipping line 216364: expected 8 fields, saw 9\\nSkipping line 219797: expected 8 fields, saw 9\\nSkipping line 219926: expected 8 fields, saw 10\\nSkipping line 220330: expected 8 fields, saw 9\\nSkipping line 220626: expected 8 fields, saw 9\\nSkipping line 221180: expected 8 fields, saw 10\\nSkipping line 221502: expected 8 fields, saw 9\\nSkipping line 227933: expected 8 fields, saw 11\\nSkipping line 228687: expected 8 fields, saw 10\\nSkipping line 228957: expected 8 fields, saw 10\\nSkipping line 229655: expected 8 fields, saw 9\\nSkipping line 232561: expected 8 fields, saw 9\\nSkipping line 238333: expected 8 fields, saw 10\\nSkipping line 238927: expected 8 fields, saw 9\\nSkipping line 239775: expected 8 fields, saw 9\\nSkipping line 241757: expected 8 fields, saw 10\\nSkipping line 244864: expected 8 fields, saw 13\\nSkipping line 245414: expected 8 fields, saw 9\\nSkipping line 245933: expected 8 fields, saw 9\\nSkipping line 246351: expected 8 fields, saw 9\\nSkipping line 251296: expected 8 fields, saw 9\\nSkipping line 251297: expected 8 fields, saw 9\\nSkipping line 253930: expected 8 fields, saw 9\\nSkipping line 259941: expected 8 fields, saw 9\\nSkipping line 260581: expected 8 fields, saw 9\\nSkipping line 261529: expected 8 fields, saw 9\\n'\n",
      "b'Skipping line 267207: expected 8 fields, saw 14\\nSkipping line 269121: expected 8 fields, saw 9\\n'\n",
      "C:\\Users\\edwar\\AppData\\Roaming\\Python\\Python39\\site-packages\\IPython\\core\\interactiveshell.py:3378: DtypeWarning: Columns (3) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ISBN</th>\n",
       "      <th>Book-Title</th>\n",
       "      <th>Book-Author</th>\n",
       "      <th>Year-Of-Publication</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Image-URL-S</th>\n",
       "      <th>Image-URL-M</th>\n",
       "      <th>Image-URL-L</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0195153448</td>\n",
       "      <td>Classical Mythology</td>\n",
       "      <td>Mark P. O. Morford</td>\n",
       "      <td>2002</td>\n",
       "      <td>Oxford University Press</td>\n",
       "      <td>http://images.amazon.com/images/P/0195153448.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0195153448.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0195153448.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0002005018</td>\n",
       "      <td>Clara Callan</td>\n",
       "      <td>Richard Bruce Wright</td>\n",
       "      <td>2001</td>\n",
       "      <td>HarperFlamingo Canada</td>\n",
       "      <td>http://images.amazon.com/images/P/0002005018.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0002005018.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0002005018.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0060973129</td>\n",
       "      <td>Decision in Normandy</td>\n",
       "      <td>Carlo D'Este</td>\n",
       "      <td>1991</td>\n",
       "      <td>HarperPerennial</td>\n",
       "      <td>http://images.amazon.com/images/P/0060973129.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0060973129.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0060973129.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0374157065</td>\n",
       "      <td>Flu: The Story of the Great Influenza Pandemic...</td>\n",
       "      <td>Gina Bari Kolata</td>\n",
       "      <td>1999</td>\n",
       "      <td>Farrar Straus Giroux</td>\n",
       "      <td>http://images.amazon.com/images/P/0374157065.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0374157065.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0374157065.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0393045218</td>\n",
       "      <td>The Mummies of Urumchi</td>\n",
       "      <td>E. J. W. Barber</td>\n",
       "      <td>1999</td>\n",
       "      <td>W. W. Norton &amp;amp, Company</td>\n",
       "      <td>http://images.amazon.com/images/P/0393045218.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0393045218.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0393045218.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271259</th>\n",
       "      <td>0440400988</td>\n",
       "      <td>There's a Bat in Bunk Five</td>\n",
       "      <td>Paula Danziger</td>\n",
       "      <td>1988</td>\n",
       "      <td>Random House Childrens Pub (Mm)</td>\n",
       "      <td>http://images.amazon.com/images/P/0440400988.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0440400988.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0440400988.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271260</th>\n",
       "      <td>0525447644</td>\n",
       "      <td>From One to One Hundred</td>\n",
       "      <td>Teri Sloat</td>\n",
       "      <td>1991</td>\n",
       "      <td>Dutton Books</td>\n",
       "      <td>http://images.amazon.com/images/P/0525447644.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0525447644.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0525447644.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271261</th>\n",
       "      <td>006008667X</td>\n",
       "      <td>Lily Dale : The True Story of the Town that Ta...</td>\n",
       "      <td>Christine Wicker</td>\n",
       "      <td>2004</td>\n",
       "      <td>HarperSanFrancisco</td>\n",
       "      <td>http://images.amazon.com/images/P/006008667X.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/006008667X.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/006008667X.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271262</th>\n",
       "      <td>0192126040</td>\n",
       "      <td>Republic (World's Classics)</td>\n",
       "      <td>Plato</td>\n",
       "      <td>1996</td>\n",
       "      <td>Oxford University Press</td>\n",
       "      <td>http://images.amazon.com/images/P/0192126040.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0192126040.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0192126040.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271263</th>\n",
       "      <td>0767409752</td>\n",
       "      <td>A Guided Tour of Rene Descartes' Meditations o...</td>\n",
       "      <td>Christopher  Biffle</td>\n",
       "      <td>2000</td>\n",
       "      <td>McGraw-Hill Humanities/Social Sciences/Languages</td>\n",
       "      <td>http://images.amazon.com/images/P/0767409752.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0767409752.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0767409752.0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>271264 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              ISBN                                         Book-Title  \\\n",
       "0       0195153448                                Classical Mythology   \n",
       "1       0002005018                                       Clara Callan   \n",
       "2       0060973129                               Decision in Normandy   \n",
       "3       0374157065  Flu: The Story of the Great Influenza Pandemic...   \n",
       "4       0393045218                             The Mummies of Urumchi   \n",
       "...            ...                                                ...   \n",
       "271259  0440400988                         There's a Bat in Bunk Five   \n",
       "271260  0525447644                            From One to One Hundred   \n",
       "271261  006008667X  Lily Dale : The True Story of the Town that Ta...   \n",
       "271262  0192126040                        Republic (World's Classics)   \n",
       "271263  0767409752  A Guided Tour of Rene Descartes' Meditations o...   \n",
       "\n",
       "                 Book-Author Year-Of-Publication  \\\n",
       "0         Mark P. O. Morford                2002   \n",
       "1       Richard Bruce Wright                2001   \n",
       "2               Carlo D'Este                1991   \n",
       "3           Gina Bari Kolata                1999   \n",
       "4            E. J. W. Barber                1999   \n",
       "...                      ...                 ...   \n",
       "271259        Paula Danziger                1988   \n",
       "271260            Teri Sloat                1991   \n",
       "271261      Christine Wicker                2004   \n",
       "271262                 Plato                1996   \n",
       "271263   Christopher  Biffle                2000   \n",
       "\n",
       "                                               Publisher  \\\n",
       "0                                Oxford University Press   \n",
       "1                                  HarperFlamingo Canada   \n",
       "2                                        HarperPerennial   \n",
       "3                                   Farrar Straus Giroux   \n",
       "4                             W. W. Norton &amp, Company   \n",
       "...                                                  ...   \n",
       "271259                   Random House Childrens Pub (Mm)   \n",
       "271260                                      Dutton Books   \n",
       "271261                                HarperSanFrancisco   \n",
       "271262                           Oxford University Press   \n",
       "271263  McGraw-Hill Humanities/Social Sciences/Languages   \n",
       "\n",
       "                                              Image-URL-S  \\\n",
       "0       http://images.amazon.com/images/P/0195153448.0...   \n",
       "1       http://images.amazon.com/images/P/0002005018.0...   \n",
       "2       http://images.amazon.com/images/P/0060973129.0...   \n",
       "3       http://images.amazon.com/images/P/0374157065.0...   \n",
       "4       http://images.amazon.com/images/P/0393045218.0...   \n",
       "...                                                   ...   \n",
       "271259  http://images.amazon.com/images/P/0440400988.0...   \n",
       "271260  http://images.amazon.com/images/P/0525447644.0...   \n",
       "271261  http://images.amazon.com/images/P/006008667X.0...   \n",
       "271262  http://images.amazon.com/images/P/0192126040.0...   \n",
       "271263  http://images.amazon.com/images/P/0767409752.0...   \n",
       "\n",
       "                                              Image-URL-M  \\\n",
       "0       http://images.amazon.com/images/P/0195153448.0...   \n",
       "1       http://images.amazon.com/images/P/0002005018.0...   \n",
       "2       http://images.amazon.com/images/P/0060973129.0...   \n",
       "3       http://images.amazon.com/images/P/0374157065.0...   \n",
       "4       http://images.amazon.com/images/P/0393045218.0...   \n",
       "...                                                   ...   \n",
       "271259  http://images.amazon.com/images/P/0440400988.0...   \n",
       "271260  http://images.amazon.com/images/P/0525447644.0...   \n",
       "271261  http://images.amazon.com/images/P/006008667X.0...   \n",
       "271262  http://images.amazon.com/images/P/0192126040.0...   \n",
       "271263  http://images.amazon.com/images/P/0767409752.0...   \n",
       "\n",
       "                                              Image-URL-L  \n",
       "0       http://images.amazon.com/images/P/0195153448.0...  \n",
       "1       http://images.amazon.com/images/P/0002005018.0...  \n",
       "2       http://images.amazon.com/images/P/0060973129.0...  \n",
       "3       http://images.amazon.com/images/P/0374157065.0...  \n",
       "4       http://images.amazon.com/images/P/0393045218.0...  \n",
       "...                                                   ...  \n",
       "271259  http://images.amazon.com/images/P/0440400988.0...  \n",
       "271260  http://images.amazon.com/images/P/0525447644.0...  \n",
       "271261  http://images.amazon.com/images/P/006008667X.0...  \n",
       "271262  http://images.amazon.com/images/P/0192126040.0...  \n",
       "271263  http://images.amazon.com/images/P/0767409752.0...  \n",
       "\n",
       "[271264 rows x 8 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books_df = pd.read_csv('BX-Books.csv',encoding='latin-1', delimiter=',',error_bad_lines = False)\n",
    "ratings_df = pd.read_csv('BX-Book-Ratings.csv',encoding='latin-1', delimiter=',',error_bad_lines = False)\n",
    "books_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               Title Rating\n",
      "0                                Classical Mythology      0\n",
      "1                                       Clara Callan      5\n",
      "2                                           Jane Doe      5\n",
      "3                                      The Testament      0\n",
      "4  Decorative Stamping: Hundreds of Projects for ...      7\n"
     ]
    }
   ],
   "source": [
    "userInput = [{'Title':'Classical Mythology', 'Rating':'0'},\n",
    "            {'Title':'Clara Callan', 'Rating':'5'},\n",
    "            {'Title':'Jane Doe','Rating':'5'},\n",
    "            {'Title':'The Testament','Rating':'0'},\n",
    "            {'Title':'Decorative Stamping: Hundreds of Projects for Your Home','Rating':'7'}]\n",
    "        \n",
    "inputBooks = pd.DataFrame(userInput)\n",
    "print(inputBooks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         ISBN                Title Rating\n",
      "0  0195153448  Classical Mythology      0\n",
      "1  0002005018         Clara Callan      5\n"
     ]
    }
   ],
   "source": [
    "inputID = books_df[books_df['Book-Title'].isin(inputBooks['Title'].tolist())]\n",
    "inputBooks = pd.merge(inputID,inputBooks,left_index=True, right_index=True)\n",
    "inputBooks = inputBooks[['ISBN','Title','Rating']]\n",
    "print(inputBooks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            User-ID  Book-Rating\n",
      "ISBN                            \n",
      "0002005018       14           14\n",
      "0195153448        1            1\n"
     ]
    }
   ],
   "source": [
    "userSubset = ratings_df[ratings_df['ISBN'].isin(inputBooks['ISBN'].tolist())]\n",
    "print(userSubset.groupby('ISBN').count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('0002005018',          User-ID        ISBN  Book-Rating\n",
      "9563           8  0002005018            5\n",
      "43178      11400  0002005018            0\n",
      "45340      11676  0002005018            8\n",
      "188244     41385  0002005018            0\n",
      "283152     67544  0002005018            8\n",
      "354414     85526  0002005018            0\n",
      "399690     96054  0002005018            0\n",
      "490342    116866  0002005018            9\n",
      "508051    123629  0002005018            9\n",
      "734221    177458  0002005018            0\n",
      "828273    200273  0002005018            8\n",
      "871535    210926  0002005018            9\n",
      "903613    219008  0002005018            7\n",
      "1096853   263325  0002005018            6), ('0195153448',       User-ID        ISBN  Book-Rating\n",
      "9561        2  0195153448            0)]\n"
     ]
    }
   ],
   "source": [
    "userSubsetGroup = userSubset.groupby(['ISBN'])\n",
    "\n",
    "def take_3_elem(x):\n",
    "    # print (len(x[1]))\n",
    "    return len(x[1])\n",
    "    \n",
    "userSubsetGroup = sorted(userSubsetGroup, key=take_3_elem, reverse=True)\n",
    "\n",
    "userSubsetGroup = userSubsetGroup[0:100]\n",
    "print(userSubsetGroup[0:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "pearsonCorrelationDict = {}\n",
    "\n",
    "#For every user group in our subset\n",
    "for name, group in userSubsetGroup:\n",
    "\n",
    "    #Let's start by sorting the input and current user group so the values aren't mixed up later on\n",
    "    group = group.sort_values(by='ISBN')\n",
    "    inputBooks = inputBooks.sort_values(by='ISBN')\n",
    "\n",
    "    #Get the N for the formula\n",
    "    nRatings = len(group)\n",
    "\n",
    "    #Get the review scores for the movies that they both have in common\n",
    "    temp_df = inputBooks[inputBooks['ISBN'].isin(group['ISBN'].tolist())]\n",
    "\n",
    "    #And then store them in a temporary buffer variable in a list format to facilitate future calculations\n",
    "    tempRatingList = temp_df['ISBN'].tolist()\n",
    "\n",
    "    tempR = []\n",
    "    for i in tempRatingList:\n",
    "        tempR.append(int(i))\n",
    "\n",
    "    tempG = []\n",
    "    #Let's also put the current user group reviews in a list format\n",
    "    tempGroupList = group['ISBN'].tolist()\n",
    "\n",
    "    for i in tempGroupList:\n",
    "        tempG.append(int(i))\n",
    "\n",
    "    \n",
    "    #Now let's calculate the pearson correlation between two users, so called, x and y manually (check the formula from week 7 slide)\n",
    "    Sxx = sum([pow(i,2) for i in tempG]) - pow(sum(tempR),2)/int(nRatings)\n",
    "    Syy = sum([pow(i,2) for i in tempG]) - pow(sum(tempG),2)/int(nRatings)\n",
    "    Sxy = sum( i*j for i, j in zip(tempR, tempG)) - sum(tempR)*sum(tempG)/int(nRatings)\n",
    "\n",
    "    #If the denominator is different than zero, then divide, else, 0 correlation.\n",
    "    if Sxx != 0 and Syy != 0:\n",
    "        pearsonCorrelationDict[name] = Sxy/sqrt(Sxx*Syy)\n",
    "    else:\n",
    "        pearsonCorrelationDict[name] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   similarityIndex      userId\n",
      "0                0  0002005018\n",
      "1                0  0195153448\n"
     ]
    }
   ],
   "source": [
    "pearsonDF = pd.DataFrame.from_dict(pearsonCorrelationDict, orient='index')\n",
    "pearsonDF.columns = ['similarityIndex']\n",
    "pearsonDF['userId'] = pearsonDF.index\n",
    "pearsonDF.index = range(len(pearsonDF))\n",
    "print(pearsonDF.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   similarityIndex      userId\n",
      "0                0  0002005018\n",
      "1                0  0195153448\n"
     ]
    }
   ],
   "source": [
    "topUsers=pearsonDF.sort_values(by='similarityIndex', ascending=False)[0:50]\n",
    "print(topUsers.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   similarityIndex      userId  User-ID        ISBN  Book-Rating\n",
      "0                0  0002005018   276725  034545104X            0\n",
      "1                0  0195153448   276726  0155061224            5\n"
     ]
    }
   ],
   "source": [
    "topUsersRating=topUsers.merge(ratings_df, left_index=True, right_index=True)\n",
    "print(topUsersRating.head(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   similarityIndex      userId  User-ID        ISBN  Book-Rating  \\\n",
      "0                0  0002005018   276725  034545104X            0   \n",
      "1                0  0195153448   276726  0155061224            5   \n",
      "\n",
      "   weightedRating  \n",
      "0               0  \n",
      "1               0  \n"
     ]
    }
   ],
   "source": [
    "topUsersRating['weightedRating'] = topUsersRating['similarityIndex']*topUsersRating['Book-Rating']\n",
    "print(topUsersRating.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            sum_similarityIndex  sum_weightedRating\n",
      "ISBN                                               \n",
      "0155061224                    0                   0\n",
      "034545104X                    0                   0\n"
     ]
    }
   ],
   "source": [
    "tempTopUsersRating = topUsersRating.groupby('ISBN').sum()[['similarityIndex','weightedRating']]\n",
    "tempTopUsersRating.columns = ['sum_similarityIndex','sum_weightedRating']\n",
    "print(tempTopUsersRating.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            weighted average recommendation score     movieId\n",
      "ISBN                                                         \n",
      "0155061224                                    NaN  0155061224\n",
      "034545104X                                    NaN  034545104X\n"
     ]
    }
   ],
   "source": [
    "recommendation_df = pd.DataFrame()\n",
    "\n",
    "recommendation_df['weighted average recommendation score'] = tempTopUsersRating['sum_weightedRating']/tempTopUsersRating['sum_similarityIndex']\n",
    "recommendation_df['movieId'] = tempTopUsersRating.index\n",
    "print(recommendation_df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            weighted average recommendation score     movieId\n",
      "ISBN                                                         \n",
      "0155061224                                    NaN  0155061224\n",
      "034545104X                                    NaN  034545104X\n"
     ]
    }
   ],
   "source": [
    "recommendation_df = recommendation_df.sort_values(by='weighted average recommendation score', ascending=False)\n",
    "print(recommendation_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'ISBN'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\pandas\\core\\indexes\\base.py:3361\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3360\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 3361\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[0;32m   3362\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\pandas\\_libs\\index.pyx:76\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\pandas\\_libs\\index.pyx:108\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5198\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5206\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'ISBN'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [85], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m recommended_books\u001b[39m=\u001b[39mbooks_df\u001b[39m.\u001b[39miloc[books_df[\u001b[39m'\u001b[39m\u001b[39mISBN\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39misin(recommendation_df[\u001b[39m'\u001b[39m\u001b[39mISBN\u001b[39m\u001b[39m'\u001b[39m])]\n\u001b[0;32m      3\u001b[0m \u001b[39m#we don't want to recommend the same movie\u001b[39;00m\n\u001b[0;32m      4\u001b[0m recommended_movie\u001b[39m=\u001b[39mrecommended_books\u001b[39m.\u001b[39miloc[\u001b[39m~\u001b[39mrecommended_books\u001b[39m.\u001b[39mISBN\u001b[39m.\u001b[39misin(userSubset[\u001b[39m'\u001b[39m\u001b[39mISBN\u001b[39m\u001b[39m'\u001b[39m])]\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\pandas\\core\\frame.py:3458\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3456\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   3457\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3458\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[0;32m   3459\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3460\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\pandas\\core\\indexes\\base.py:3363\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3361\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3362\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m-> 3363\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[0;32m   3365\u001b[0m \u001b[39mif\u001b[39;00m is_scalar(key) \u001b[39mand\u001b[39;00m isna(key) \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhasnans:\n\u001b[0;32m   3366\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'ISBN'"
     ]
    }
   ],
   "source": [
    "recommended_books=books_df.iloc[books_df['ISBN'].isin(recommendation_df['ISBN'])]\n",
    "\n",
    "#we don't want to recommend the same movie\n",
    "recommended_movie=recommended_books.iloc[~recommended_books.ISBN.isin(userSubset['ISBN'])]\n",
    "\n",
    "print(recommended_movie)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "11938c6bc6919ae2720b4d5011047913343b08a43b18698fd82dedb0d4417594"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
